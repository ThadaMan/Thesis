{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DXF Parser Module – Structural Geometry Pipeline\n",
        "**Author**: Thaddeus da Silva Correa\n",
        "\n",
        "**Project**: Automated Extraction and Interpretation of Structural Geometry from CAD Drawings for BIM Integration  \n",
        "**Module**: 1 of 4 – DXF Parser  \n",
        "**Environment**: Google Colab  \n",
        "**Last updated**: June 2025\n",
        "\n",
        "---\n",
        "\n",
        "This module reads DXF drawings and extracts geometric primitives into a structured intermediate format (`geometry.json`). It detects lines, arcs, polylines, and text, reconstructs closed profiles, and classifies them for further 3D interpretation.\n",
        "\n",
        "**Inputs**: DXF files  \n",
        "**Outputs**: geometry JSONs with raw edges, closed chains, and metadata  \n",
        "\n"
      ],
      "metadata": {
        "id": "y8BNvsKSPS0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup  \n",
        "Import necessary libraries and define file system paths.\n",
        "\n"
      ],
      "metadata": {
        "id": "u9pnn-ZqP4s5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44JiONcQ13AR",
        "outputId": "b09b1990-9c45-4e05-a5f0-0c67983544d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ezdxf in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from ezdxf) (3.2.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ezdxf) (4.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ezdxf) (2.0.2)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.11/dist-packages (from ezdxf) (4.58.4)\n"
          ]
        }
      ],
      "source": [
        "# Install required library for DXF parsing\n",
        "!pip install ezdxf\n",
        "\n",
        "# Core libraries\n",
        "import ezdxf\n",
        "import json\n",
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Geometry & math utilities\n",
        "import numpy as np\n",
        "from scipy.spatial import KDTree\n",
        "import re\n",
        "from shapely.geometry import Polygon, Point\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Core Parsing Functions\n",
        "\n",
        "In this section, we define the core functions used to parse and process the geometry from DXF files. These functions are organized into the following categories:\n",
        "\n",
        "- ** A. Geometry Utilities**\n",
        "- ** B. DXF Entity Parsers**\n",
        "- ** C. Chain Builder**\n",
        "- ** D. Cutout Detection**\n",
        "- ** E. Profile Classification & Feature Grouping**\n",
        "- ** F. DXF Entity Handler**\n",
        "- ** G. Batch Processing & Layer Summary**\n",
        "- ** H. Metadata Tagging**\n",
        "\n"
      ],
      "metadata": {
        "id": "QI1y6mxadGtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Geometry Utilities\n",
        "Basic point math: distance, rounding, centroid, and polygon area.\n"
      ],
      "metadata": {
        "id": "U3afNU6PTrc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOLERANCE = 0.1  # Default spatial tolerance in mm\n",
        "\n",
        "\n",
        "def round_point(pt, tol=TOLERANCE):\n",
        "    \"\"\"\n",
        "    Round a 2D or 3D point to the nearest grid defined by the given tolerance.\n",
        "\n",
        "    Args:\n",
        "        pt (tuple or list): Input point (x, y) or (x, y, z)\n",
        "        tol (float): Tolerance grid spacing\n",
        "\n",
        "    Returns:\n",
        "        tuple: Rounded point\n",
        "    \"\"\"\n",
        "    return tuple([round(coord / tol) * tol for coord in pt])\n",
        "\n",
        "\n",
        "def point_distance(p1, p2):\n",
        "    \"\"\"\n",
        "    Calculate Euclidean distance between two 2D or 3D points.\n",
        "\n",
        "    Args:\n",
        "        p1, p2 (tuple or list): Points (x, y) or (x, y, z)\n",
        "\n",
        "    Returns:\n",
        "        float: Euclidean distance\n",
        "    \"\"\"\n",
        "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(p1, p2)))\n",
        "\n",
        "\n",
        "def compute_centroid(points):\n",
        "    \"\"\"\n",
        "    Compute the centroid (center of mass) of a set of 2D or 3D points.\n",
        "\n",
        "    Args:\n",
        "        points (list): List of points, each being (x, y) or (x, y, z)\n",
        "\n",
        "    Returns:\n",
        "        list: Centroid point as [x, y, z]\n",
        "    \"\"\"\n",
        "    if not points:\n",
        "        return [0, 0, 0]\n",
        "\n",
        "    n = len(points)\n",
        "    cx = sum(p[0] for p in points) / n\n",
        "    cy = sum(p[1] for p in points) / n\n",
        "    cz = sum((p[2] if len(p) > 2 else 0) for p in points) / n\n",
        "    return [cx, cy, cz]\n",
        "\n",
        "\n",
        "def polygon_area(points):\n",
        "    \"\"\"\n",
        "    Compute the signed area of a polygon using the shoelace formula.\n",
        "\n",
        "    Args:\n",
        "        points (list): List of (x, y) points forming the polygon\n",
        "\n",
        "    Returns:\n",
        "        float: Absolute value of area\n",
        "    \"\"\"\n",
        "    area = 0.0\n",
        "    n = len(points)\n",
        "    for i in range(n):\n",
        "        x0, y0 = points[i][:2]\n",
        "        x1, y1 = points[(i + 1) % n][:2]\n",
        "        area += (x0 * y1) - (x1 * y0)\n",
        "    return abs(area) / 2.0\n"
      ],
      "metadata": {
        "id": "eu7VNo96TvdT"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. DXF Entity Parsers  \n",
        "Functions to parse `LINE`, `ARC`, `LWPOLYLINE`, `POLYLINE`, and `SPLINE` DXF entities into segments or chains of lines.\n"
      ],
      "metadata": {
        "id": "c9wScatLU1St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_line(entity):\n",
        "    \"\"\"\n",
        "    Parse a DXF LINE entity into a 2-point edge.\n",
        "\n",
        "    Args:\n",
        "        entity (ezdxf.entities.Line): LINE entity from DXF.\n",
        "\n",
        "    Returns:\n",
        "        dict: Edge dictionary with start/end coordinates and layer.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"type\": \"line\",\n",
        "        \"start\": list(entity.dxf.start),\n",
        "        \"end\": list(entity.dxf.end),\n",
        "        \"layer\": entity.dxf.layer\n",
        "    }\n",
        "\n",
        "\n",
        "def parse_arc(entity, min_segments=8, max_segments=64, config=None):\n",
        "    \"\"\"\n",
        "    Approximate a DXF ARC entity as a polyline (list of straight segments).\n",
        "\n",
        "    Args:\n",
        "        entity (ezdxf.entities.Arc): ARC entity.\n",
        "        min_segments (int): Minimum number of segments for approximation.\n",
        "        max_segments (int): Maximum number of segments for approximation.\n",
        "        config (dict): Optional config dictionary for arc segmentation control.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - list of line segments approximating the arc\n",
        "            - arc metadata dictionary (center, radius, start/end angles)\n",
        "    \"\"\"\n",
        "    center = entity.dxf.center\n",
        "    radius = entity.dxf.radius\n",
        "    start_angle_deg = entity.dxf.start_angle\n",
        "    end_angle_deg = entity.dxf.end_angle\n",
        "\n",
        "    start_angle = math.radians(start_angle_deg)\n",
        "    end_angle = math.radians(end_angle_deg)\n",
        "\n",
        "    sweep = (end_angle - start_angle) % (2 * math.pi)\n",
        "    arc_length = radius * sweep\n",
        "\n",
        "    seg_per_180 = config.get(\"arc_segments_per_180\", 20) if config else 20\n",
        "    segment_length = max(arc_length / seg_per_180, 0.5)\n",
        "    num_segments = int(max(min_segments, min(max_segments, arc_length / segment_length)))\n",
        "\n",
        "    points = []\n",
        "    for i in range(num_segments + 1):\n",
        "        angle = start_angle + sweep * i / num_segments\n",
        "        pt = [\n",
        "            center[0] + radius * math.cos(angle),\n",
        "            center[1] + radius * math.sin(angle),\n",
        "            center[2]\n",
        "        ]\n",
        "        points.append(pt)\n",
        "\n",
        "    arc_meta = {\n",
        "        \"center\": list(center),\n",
        "        \"radius\": radius,\n",
        "        \"start_angle\": start_angle_deg,\n",
        "        \"end_angle\": end_angle_deg,\n",
        "        \"layer\": entity.dxf.layer\n",
        "    }\n",
        "\n",
        "    segments = [\n",
        "        {\n",
        "            \"type\": \"line\",\n",
        "            \"start\": points[i],\n",
        "            \"end\": points[i + 1],\n",
        "            \"layer\": entity.dxf.layer,\n",
        "            \"source\": \"arc\",\n",
        "            \"arc_meta\": arc_meta\n",
        "        }\n",
        "        for i in range(num_segments)\n",
        "    ]\n",
        "\n",
        "    return segments, arc_meta\n",
        "\n",
        "\n",
        "def parse_lwpolyline(entity):\n",
        "    \"\"\"\n",
        "    Parse a DXF LWPOLYLINE entity into a list of connected line segments.\n",
        "\n",
        "    Args:\n",
        "        entity (ezdxf.entities.LWPolyline): Lightweight polyline.\n",
        "\n",
        "    Returns:\n",
        "        list: List of edge dictionaries.\n",
        "    \"\"\"\n",
        "    pts = [[p[0], p[1], 0] for p in entity.get_points()]\n",
        "    edges = [{\"type\": \"line\", \"start\": pts[i], \"end\": pts[i + 1], \"layer\": entity.dxf.layer} for i in range(len(pts) - 1)]\n",
        "    if entity.closed:\n",
        "        edges.append({\"type\": \"line\", \"start\": pts[-1], \"end\": pts[0], \"layer\": entity.dxf.layer})\n",
        "    return edges\n",
        "\n",
        "\n",
        "def parse_polyline(entity, closure_tolerance=1e-2):\n",
        "    \"\"\"\n",
        "    Parse a legacy POLYLINE entity into edge segments. Auto-closes if points are near each other.\n",
        "\n",
        "    Args:\n",
        "        entity (ezdxf.entities.Polyline): POLYLINE entity.\n",
        "        closure_tolerance (float): Distance to consider implicit closure.\n",
        "\n",
        "    Returns:\n",
        "        list: List of edge dictionaries.\n",
        "    \"\"\"\n",
        "    pts = [list(vertex.dxf.location) for vertex in entity.vertices]\n",
        "    edges = [{\"type\": \"line\", \"start\": pts[i], \"end\": pts[i + 1], \"layer\": entity.dxf.layer} for i in range(len(pts) - 1)]\n",
        "\n",
        "    first, last = pts[0], pts[-1]\n",
        "    is_explicitly_closed = entity.is_closed\n",
        "    is_implicitly_closed = point_distance(first, last) < closure_tolerance\n",
        "\n",
        "    if is_explicitly_closed or is_implicitly_closed:\n",
        "        edges.append({\"type\": \"line\", \"start\": last, \"end\": first, \"layer\": entity.dxf.layer})\n",
        "\n",
        "    return edges\n",
        "\n",
        "\n",
        "def parse_spline(entity, max_angle_step=5):\n",
        "    \"\"\"\n",
        "    Approximate a SPLINE entity as straight-line segments using flattening.\n",
        "\n",
        "    Args:\n",
        "        entity (ezdxf.entities.Spline): SPLINE entity.\n",
        "        max_angle_step (float): Maximum angle (degrees) between segments.\n",
        "\n",
        "    Returns:\n",
        "        list: List of segment dictionaries approximating the spline.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        points = list(entity.flattening(max_angle=math.radians(max_angle_step)))\n",
        "        segments = [\n",
        "            {\n",
        "                \"type\": \"line\",\n",
        "                \"start\": list(points[i]),\n",
        "                \"end\": list(points[i + 1]),\n",
        "                \"layer\": entity.dxf.layer,\n",
        "                \"source\": \"spline\"\n",
        "            }\n",
        "            for i in range(len(points) - 1)\n",
        "        ]\n",
        "        return segments\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "\n",
        "def arc_to_edges(arc, min_segments=8, max_segments=64):\n",
        "    \"\"\"\n",
        "    Convert arc dictionary (from metadata) to segmented line edges.\n",
        "\n",
        "    Args:\n",
        "        arc (dict): Arc metadata with center, radius, angles, and layer.\n",
        "        min_segments (int): Minimum number of segments.\n",
        "        max_segments (int): Maximum number of segments.\n",
        "\n",
        "    Returns:\n",
        "        list: List of line segments approximating the arc.\n",
        "    \"\"\"\n",
        "    center = arc[\"center\"]\n",
        "    radius = arc[\"radius\"]\n",
        "    start_angle = math.radians(arc[\"start_angle\"])\n",
        "    end_angle = math.radians(arc[\"end_angle\"])\n",
        "    sweep = (end_angle - start_angle) % (2 * math.pi)\n",
        "    arc_length = radius * sweep\n",
        "    segment_length = max(arc_length / 20, 0.5)\n",
        "    num_segments = int(max(min_segments, min(max_segments, arc_length / segment_length)))\n",
        "\n",
        "    points = [\n",
        "        [\n",
        "            center[0] + radius * math.cos(start_angle + sweep * i / num_segments),\n",
        "            center[1] + radius * math.sin(start_angle + sweep * i / num_segments),\n",
        "            0\n",
        "        ]\n",
        "        for i in range(num_segments + 1)\n",
        "    ]\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"type\": \"line\",\n",
        "            \"start\": points[i],\n",
        "            \"end\": points[i + 1],\n",
        "            \"layer\": arc.get(\"layer\", \"\"),\n",
        "            \"source\": \"hatch_arc\"\n",
        "        }\n",
        "        for i in range(num_segments)\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "9_1O-OkbU1o6"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. Chain Builder  \n",
        "Group edges into continuous chains and detect closed profiles such as extrusions or revolutions. Chains are created by connecting colinear or adjacent segments and are heuristically classified.\n"
      ],
      "metadata": {
        "id": "h-x490KDVudt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_chains(edges, tol=TOLERANCE):\n",
        "    \"\"\"\n",
        "    Group edge segments into continuous chains. Detects closed loops (profiles) and classifies them as extrusion or revolution.\n",
        "\n",
        "    Args:\n",
        "        edges (list): List of raw or arc-derived edge dictionaries.\n",
        "        tol (float): Tolerance for point snapping and matching.\n",
        "\n",
        "    Returns:\n",
        "        list: List of chain dictionaries with metadata (type, closed status, arc info).\n",
        "    \"\"\"\n",
        "    snapped_edges = []\n",
        "    point_to_edges = defaultdict(list)\n",
        "    all_points = set()\n",
        "\n",
        "    # Snap points and build lookup\n",
        "    for e in edges:\n",
        "        s = round_point(e[\"start\"], tol)\n",
        "        t = round_point(e[\"end\"], tol)\n",
        "        if s == t or math.dist(s, t) < 1e-6:\n",
        "            continue\n",
        "\n",
        "        edge_idx = len(snapped_edges)\n",
        "        snapped_edges.append({\"start\": s, \"end\": t, \"orig\": e})\n",
        "        point_to_edges[s].append(edge_idx)\n",
        "        point_to_edges[t].append(edge_idx)\n",
        "        all_points.add(s)\n",
        "        all_points.add(t)\n",
        "\n",
        "    point_list = list(all_points)\n",
        "    point_idx_map = {pt: i for i, pt in enumerate(point_list)}\n",
        "    kdtree = KDTree(point_list)\n",
        "\n",
        "    visited = set()\n",
        "    chains = []\n",
        "\n",
        "    # Try to grow chains from unvisited segments\n",
        "    for i, edge in enumerate(snapped_edges):\n",
        "        if i in visited:\n",
        "            continue\n",
        "\n",
        "        chain = [edge[\"start\"], edge[\"end\"]]\n",
        "        visited.add(i)\n",
        "\n",
        "        def extend_chain(from_start):\n",
        "            \"\"\"Helper to extend chain forward or backward via nearest point.\"\"\"\n",
        "            extended = True\n",
        "            while extended:\n",
        "                extended = False\n",
        "                ref_point = chain[0] if from_start else chain[-1]\n",
        "                dist, idx = kdtree.query(ref_point, distance_upper_bound=tol + 1e-6)\n",
        "                if dist >= tol or idx >= len(point_list):\n",
        "                    return\n",
        "                nearest_pt = point_list[idx]\n",
        "\n",
        "                for j in point_to_edges.get(nearest_pt, []):\n",
        "                    if j in visited:\n",
        "                        continue\n",
        "                    e = snapped_edges[j]\n",
        "                    if nearest_pt == e[\"start\"]:\n",
        "                        next_pt = e[\"end\"]\n",
        "                    elif nearest_pt == e[\"end\"]:\n",
        "                        next_pt = e[\"start\"]\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    if from_start:\n",
        "                        chain.insert(0, next_pt)\n",
        "                    else:\n",
        "                        chain.append(next_pt)\n",
        "                    visited.add(j)\n",
        "                    extended = True\n",
        "                    break\n",
        "\n",
        "        extend_chain(from_start=False)\n",
        "        extend_chain(from_start=True)\n",
        "\n",
        "        # Compute metadata\n",
        "        is_closed = point_distance(chain[0], chain[-1]) < tol\n",
        "        length = sum(point_distance(chain[k], chain[k + 1]) for k in range(len(chain) - 1))\n",
        "\n",
        "        # Gather arc metadata\n",
        "        chain_segment_indices = [\n",
        "            idx for idx, seg in enumerate(snapped_edges)\n",
        "            if seg[\"start\"] in chain and seg[\"end\"] in chain\n",
        "        ]\n",
        "        source_types = set(\n",
        "            snapped_edges[i][\"orig\"].get(\"source\", \"manual\")\n",
        "            for i in chain_segment_indices\n",
        "            if \"orig\" in snapped_edges[i]\n",
        "        )\n",
        "        arc_metas = [\n",
        "            snapped_edges[i][\"orig\"].get(\"arc_meta\")\n",
        "            for i in chain_segment_indices\n",
        "            if \"arc_meta\" in snapped_edges[i][\"orig\"]\n",
        "        ]\n",
        "        arc_summary = None\n",
        "        if arc_metas:\n",
        "            arc_summary = {\n",
        "                \"count\": len(arc_metas),\n",
        "                \"avg_radius\": round(sum(a[\"radius\"] for a in arc_metas) / len(arc_metas), 3),\n",
        "                \"layers\": list(set(a[\"layer\"] for a in arc_metas))\n",
        "            }\n",
        "\n",
        "        layer = snapped_edges[i][\"orig\"].get(\"layer\", \"\")\n",
        "        chain_type = \"open\"\n",
        "\n",
        "        # Heuristic classification (extrusion vs revolution)\n",
        "        if is_closed:\n",
        "            arc_count = len(arc_metas)\n",
        "            arc_ratio = arc_count / max(1, len(chain))\n",
        "            layer_lower = layer.lower()\n",
        "            is_probably_revolution = (\n",
        "                arc_count >= 1 and (\n",
        "                    arc_ratio > 0.25 or\n",
        "                    len(chain) <= 4 or\n",
        "                    \"schraffur\" in layer_lower or\n",
        "                    (arc_summary and arc_summary[\"avg_radius\"] < 15)\n",
        "                )\n",
        "            )\n",
        "            if not is_probably_revolution and arc_count == 0:\n",
        "                if 3 <= len(chain) <= 6 and length < 30:\n",
        "                    xs = [p[0] for p in chain]\n",
        "                    ys = [p[1] for p in chain]\n",
        "                    bbox_width = max(xs) - min(xs)\n",
        "                    bbox_height = max(ys) - min(ys)\n",
        "                    aspect_ratio = bbox_width / max(bbox_height, 1e-3)\n",
        "                    if 0.8 <= aspect_ratio <= 1.2:\n",
        "                        is_probably_revolution = True\n",
        "\n",
        "            chain_type = \"revolution\" if is_probably_revolution else \"extrusion\"\n",
        "\n",
        "        chain_data = {\n",
        "            \"points\": chain,\n",
        "            \"is_closed\": is_closed,\n",
        "            \"length\": round(length, 2),\n",
        "            \"is_cutout\": False,\n",
        "            \"repaired\": is_closed,\n",
        "            \"type\": chain_type,\n",
        "            \"role\": \"profile\",\n",
        "            \"layer\": layer,\n",
        "            \"source_types\": list(source_types),\n",
        "            \"contains_arc\": \"arc\" in source_types\n",
        "        }\n",
        "        if len(source_types) == 1:\n",
        "            chain_data[\"source\"] = list(source_types)[0]\n",
        "        if arc_summary:\n",
        "            chain_data[\"arc_meta_summary\"] = arc_summary\n",
        "\n",
        "        chains.append(chain_data)\n",
        "\n",
        "    # Attempt to merge adjacent open chains\n",
        "    merged_chains = []\n",
        "    for chain in chains:\n",
        "        if not chain[\"is_closed\"]:\n",
        "            for other_chain in chains:\n",
        "                if chain == other_chain or other_chain[\"is_closed\"]:\n",
        "                    continue\n",
        "                if point_distance(chain[\"points\"][-1], other_chain[\"points\"][0]) < tol:\n",
        "                    chain[\"points\"].extend(other_chain[\"points\"])\n",
        "                    chain[\"length\"] += other_chain[\"length\"]\n",
        "                    chain[\"is_closed\"] = point_distance(chain[\"points\"][0], chain[\"points\"][-1]) < tol\n",
        "                    chains.remove(other_chain)\n",
        "                    merged_chains.append(chain)\n",
        "                    break\n",
        "\n",
        "    chains.extend(merged_chains)\n",
        "    return chains\n",
        "\n",
        "\n",
        "def is_valid_edge(e, tol=1e-3):\n",
        "    \"\"\"\n",
        "    Filter out degenerate or zero-length edges.\n",
        "\n",
        "    Args:\n",
        "        e (dict): Edge dictionary with start/end points.\n",
        "        tol (float): Minimum distance allowed.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if edge is valid.\n",
        "    \"\"\"\n",
        "    return point_distance(e[\"start\"], e[\"end\"]) >= tol\n"
      ],
      "metadata": {
        "id": "j9cMAcecVv9e"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D. Cutout Detection  \n",
        "Detect cutouts (holes) in the geometry by analyzing circular features and nesting relationships. This includes round holes (circles or revolutions) as well as enclosed polygonal cutouts.\n"
      ],
      "metadata": {
        "id": "9O_U1ZniWo5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_cutouts(chains, circles=None, min_radius=1.0, max_radius=50.0):\n",
        "    \"\"\"\n",
        "    Identify cutouts (holes) in geometry based on circular approximation or spatial nesting.\n",
        "\n",
        "    Args:\n",
        "        chains (list): List of chain dictionaries (each with points and metadata).\n",
        "        circles (list, optional): List of circle-like shapes with radius.\n",
        "        min_radius (float): Minimum radius to qualify as a cutout.\n",
        "        max_radius (float): Maximum radius to qualify as a cutout.\n",
        "\n",
        "    Returns:\n",
        "        dict: Summary of detected cutouts: {'chains': int, 'circles': int}\n",
        "    \"\"\"\n",
        "\n",
        "    def estimate_radius(points, centroid):\n",
        "        \"\"\"Estimate radius of a loop based on average distance to centroid.\"\"\"\n",
        "        return sum(math.dist(p[:2], centroid[:2]) for p in points) / len(points)\n",
        "\n",
        "    def get_bbox(points):\n",
        "        \"\"\"Compute 2D bounding box from list of points.\"\"\"\n",
        "        xs, ys = zip(*[p[:2] for p in points])\n",
        "        return min(xs), min(ys), max(xs), max(ys)\n",
        "\n",
        "    def bbox_inside(inner_bbox, outer_bbox):\n",
        "        \"\"\"Check if inner bounding box is fully inside the outer one.\"\"\"\n",
        "        return (inner_bbox[0] >= outer_bbox[0] and\n",
        "                inner_bbox[1] >= outer_bbox[1] and\n",
        "                inner_bbox[2] <= outer_bbox[2] and\n",
        "                inner_bbox[3] <= outer_bbox[3])\n",
        "\n",
        "    def point_in_polygon(point, polygon):\n",
        "        \"\"\"Ray casting algorithm to determine if point is inside polygon.\"\"\"\n",
        "        x, y = point[:2]\n",
        "        inside = False\n",
        "        n = len(polygon)\n",
        "        px, py = zip(*[p[:2] for p in polygon])\n",
        "        j = n - 1\n",
        "        for i in range(n):\n",
        "            if ((py[i] > y) != (py[j] > y)) and \\\n",
        "               (x < (px[j] - px[i]) * (y - py[i]) / ((py[j] - py[i]) + 1e-9) + px[i]):\n",
        "                inside = not inside\n",
        "            j = i\n",
        "        return inside\n",
        "\n",
        "    detected = {\"chains\": 0, \"circles\": 0}\n",
        "\n",
        "    # Pass 1: Detect circular chains based on shape and radius uniformity\n",
        "    for chain in chains:\n",
        "        if not chain.get(\"is_closed\") or len(chain.get(\"points\", [])) < 3:\n",
        "            continue\n",
        "\n",
        "        points = chain[\"points\"]\n",
        "        centroid = compute_centroid(points)\n",
        "        estimated_radius = estimate_radius(points, centroid)\n",
        "        max_dev = max(abs(math.dist(p[:2], centroid[:2]) - estimated_radius) for p in points)\n",
        "\n",
        "        if min_radius <= estimated_radius <= max_radius and max_dev < 1.0:\n",
        "            chain[\"is_cutout\"] = True\n",
        "            chain[\"role\"] = \"cutout\"\n",
        "            detected[\"chains\"] += 1\n",
        "\n",
        "    # Pass 2: Detect polygonal cutouts nested inside larger shapes\n",
        "    closed_chains = [c for c in chains if c.get(\"is_closed\")]\n",
        "    for i, inner in enumerate(closed_chains):\n",
        "        if inner.get(\"is_cutout\"):\n",
        "            continue\n",
        "\n",
        "        inner_bbox = get_bbox(inner[\"points\"])\n",
        "        for j, outer in enumerate(closed_chains):\n",
        "            if i == j or outer.get(\"is_cutout\"):\n",
        "                continue\n",
        "\n",
        "            outer_bbox = get_bbox(outer[\"points\"])\n",
        "            if bbox_inside(inner_bbox, outer_bbox):\n",
        "                centroid = compute_centroid(inner[\"points\"])\n",
        "                if point_in_polygon(centroid, outer[\"points\"]):\n",
        "                    inner[\"is_cutout\"] = True\n",
        "                    inner[\"role\"] = \"cutout\"\n",
        "                    detected[\"chains\"] += 1\n",
        "                    break\n",
        "                elif point_in_polygon(inner[\"points\"][0], outer[\"points\"]):\n",
        "                    inner[\"is_cutout\"] = True\n",
        "                    inner[\"role\"] = \"cutout\"\n",
        "                    detected[\"chains\"] += 1\n",
        "                    break\n",
        "\n",
        "    # Pass 3: Detect circle primitives directly\n",
        "    if circles:\n",
        "        for circle in circles:\n",
        "            radius = circle.get(\"radius\", 0)\n",
        "            if min_radius <= radius <= max_radius:\n",
        "                circle[\"is_cutout\"] = True\n",
        "                circle[\"role\"] = \"cutout\"\n",
        "                detected[\"circles\"] += 1\n",
        "\n",
        "    return detected\n"
      ],
      "metadata": {
        "id": "6cTtoDwYWpn2"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E. Profile Classification & Feature Grouping  \n",
        "Classify profile chains into extrusion or revolution types, and associate auxiliary geometry such as centerlines, tags, and dimensions for downstream processing.\n"
      ],
      "metadata": {
        "id": "4RHIyTI8XC3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_profiles(chains, geometry=None):\n",
        "    \"\"\"\n",
        "    Classify closed chains as 'extrusion' or 'revolution' based on shape.\n",
        "    Also identifies centerlines and links semantic tags to geometry.\n",
        "\n",
        "    Args:\n",
        "        chains (list): List of chain dictionaries.\n",
        "        geometry (dict, optional): DXF geometry with semantic_tags and circles for linking.\n",
        "    \"\"\"\n",
        "    open_lines = [c for c in chains if not c[\"is_closed\"] and len(c[\"points\"]) == 2]\n",
        "\n",
        "    for chain in chains:\n",
        "        if not chain[\"is_closed\"]:\n",
        "            continue\n",
        "\n",
        "        # Compute centroid of the profile\n",
        "        pts = chain[\"points\"]\n",
        "        cx = sum(p[0] for p in pts) / len(pts)\n",
        "        cy = sum(p[1] for p in pts) / len(pts)\n",
        "        centroid = (cx, cy)\n",
        "        chain[\"centroid\"] = centroid\n",
        "\n",
        "        # Determine shape type based on radial uniformity\n",
        "        rad_tol = 0.3\n",
        "        distances = [math.sqrt((p[0] - cx) ** 2 + (p[1] - cy) ** 2) for p in pts]\n",
        "        if max(distances) - min(distances) < rad_tol:\n",
        "            chain[\"type\"] = \"revolution\"\n",
        "        else:\n",
        "            chain[\"type\"] = \"extrusion\"\n",
        "\n",
        "        # Tag likely centerlines by layer name or proximity to revolution center\n",
        "        if any(word in chain[\"layer\"].lower() for word in [\"axis\", \"center\", \"achse\", \"achsen\"]):\n",
        "            chain[\"role\"] = \"centerline\"\n",
        "            continue\n",
        "\n",
        "        if chain[\"type\"] == \"revolution\":\n",
        "            for line in open_lines:\n",
        "                a, b = line[\"points\"]\n",
        "                x1, y1 = a[:2]\n",
        "                x2, y2 = b[:2]\n",
        "                x0, y0 = centroid\n",
        "                num = abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1)\n",
        "                den = math.sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
        "                dist_to_line = num / den if den > 1e-6 else float('inf')\n",
        "                if dist_to_line < 0.3:\n",
        "                    line[\"role\"] = \"centerline\"\n",
        "                    break\n",
        "\n",
        "    # Optional: Link semantic tags to chains or circles by proximity\n",
        "    if geometry and \"semantic_tags\" in geometry:\n",
        "        chain_centroids = [\n",
        "            (i, c[\"centroid\"]) for i, c in enumerate(chains) if c.get(\"is_closed\") and \"centroid\" in c\n",
        "        ]\n",
        "        circle_list = geometry.get(\"circles\", [])\n",
        "\n",
        "        for tag in geometry[\"semantic_tags\"]:\n",
        "            tx, ty = tag[\"position\"][:2]\n",
        "            best = None\n",
        "            best_dist = float(\"inf\")\n",
        "\n",
        "            for idx, (cx, cy) in chain_centroids:\n",
        "                dist = ((tx - cx)**2 + (ty - cy)**2) ** 0.5\n",
        "                if dist < best_dist:\n",
        "                    best = {\"type\": \"chain\", \"index\": idx, \"distance\": dist}\n",
        "                    best_dist = dist\n",
        "\n",
        "            for i, circ in enumerate(circle_list):\n",
        "                cx, cy = circ[\"center\"][:2]\n",
        "                dist = ((tx - cx)**2 + (ty - cy)**2) ** 0.5\n",
        "                if dist < best_dist:\n",
        "                    best = {\"type\": \"circle\", \"index\": i, \"distance\": dist}\n",
        "                    best_dist = dist\n",
        "\n",
        "            if best and best[\"distance\"] < 15:\n",
        "                tag[\"linked_geometry\"] = best\n",
        "\n",
        "def group_features(geometry, proximity_thresh=20):\n",
        "    \"\"\"\n",
        "    Group nearby features such as holes, semantic tags, and dimensions into part-level features.\n",
        "\n",
        "    Args:\n",
        "        geometry (dict): Parsed geometry containing holes, semantic_tags, and dimensions.\n",
        "        proximity_thresh (float): Max distance to associate tags/dimensions with holes.\n",
        "\n",
        "    Returns:\n",
        "        list: Feature groups (hole with associated tags/dimensions).\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    used_tags = set()\n",
        "    used_dims = set()\n",
        "\n",
        "    for i, hole in enumerate(geometry.get(\"holes\", [])):\n",
        "        hx, hy = hole[\"center\"][:2]\n",
        "        hole_feature = {\n",
        "            \"geometry_ref\": {\"type\": hole[\"source\"], \"index\": i},\n",
        "            \"linked_texts\": [],\n",
        "            \"linked_dimensions\": [],\n",
        "            \"role\": hole[\"role\"]\n",
        "        }\n",
        "\n",
        "        # Link nearby semantic tags\n",
        "        for j, tag in enumerate(geometry.get(\"semantic_tags\", [])):\n",
        "            if j in used_tags:\n",
        "                continue\n",
        "            tx, ty = tag[\"position\"][:2]\n",
        "            dist = ((hx - tx) ** 2 + (hy - ty) ** 2) ** 0.5\n",
        "            if dist < proximity_thresh:\n",
        "                hole_feature[\"linked_texts\"].append(tag)\n",
        "                used_tags.add(j)\n",
        "\n",
        "        # Link nearby dimensions\n",
        "        for k, dim in enumerate(geometry.get(\"dimensions\", [])):\n",
        "            if k in used_dims:\n",
        "                continue\n",
        "            dx, dy = dim[\"insert\"][:2]\n",
        "            dist = ((hx - dx) ** 2 + (hy - dy) ** 2) ** 0.5\n",
        "            if dist < proximity_thresh:\n",
        "                hole_feature[\"linked_dimensions\"].append(dim)\n",
        "                used_dims.add(k)\n",
        "\n",
        "        features.append(hole_feature)\n",
        "\n",
        "    geometry[\"features\"] = features\n",
        "    return features"
      ],
      "metadata": {
        "id": "XU3y2uM9XB44"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F. DXF Entity Handler  \n",
        "Read a DXF file, parse its contents by entity type, and structure the output geometry dictionary with categorized features, chains, holes, and semantic tags.\n"
      ],
      "metadata": {
        "id": "GvXQ4Iq1X19J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_dxf_entities(filepath, tolerance=0.1, layer_config=None, config=None):\n",
        "    \"\"\"\n",
        "    Parses a DXF file into a structured geometry dictionary.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the DXF file to parse.\n",
        "        tolerance (float): Tolerance for edge merging and chain building.\n",
        "        layer_config (dict): Optional dictionary to filter layers.\n",
        "        config (dict): Optional configuration dict for arc resolution, hole thresholds, etc.\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains geometry metadata, parsed parts, and analysis results.\n",
        "    \"\"\"\n",
        "    geometry = defaultdict(list)\n",
        "    warnings = []\n",
        "    all_edges = []\n",
        "    bbox_min = [float('inf'), float('inf')]\n",
        "    bbox_max = [float('-inf'), float('-inf')]\n",
        "\n",
        "    # Load DXF\n",
        "    try:\n",
        "        doc = ezdxf.readfile(filepath)\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"filename\": filepath,\n",
        "            \"error\": str(e),\n",
        "            \"geometry\": {},\n",
        "            \"warnings\": [str(e)]\n",
        "        }\n",
        "\n",
        "    msp = doc.modelspace()\n",
        "    units_code = doc.header.get('$INSUNITS', 0)\n",
        "    units_map = {0: \"unitless\", 1: \"inches\", 2: \"feet\", 4: \"mm\", 5: \"cm\", 6: \"m\"}\n",
        "    units = units_map.get(units_code, \"unknown\")\n",
        "\n",
        "    def update_bounds(pt):\n",
        "        \"\"\"Track drawing bounding box.\"\"\"\n",
        "        nonlocal bbox_min, bbox_max\n",
        "        bbox_min[0] = min(bbox_min[0], pt[0])\n",
        "        bbox_min[1] = min(bbox_min[1], pt[1])\n",
        "        bbox_max[0] = max(bbox_max[0], pt[0])\n",
        "        bbox_max[1] = max(bbox_max[1], pt[1])\n",
        "\n",
        "    # Loop through all modelspace entities\n",
        "    for entity in list(msp):\n",
        "        try:\n",
        "            # Optional layer filtering\n",
        "            layer = entity.dxf.layer\n",
        "            if layer_config:\n",
        "                if \"allowed_layers\" in layer_config and layer not in layer_config[\"allowed_layers\"]:\n",
        "                    continue\n",
        "                if \"ignored_layers\" in layer_config and layer in layer_config[\"ignored_layers\"]:\n",
        "                    continue\n",
        "\n",
        "            # Parse entity by type\n",
        "            etype = entity.dxftype()\n",
        "            if etype == 'LINE':\n",
        "                edge = parse_line(entity)\n",
        "                if is_valid_edge(edge):\n",
        "                  all_edges.append(edge)\n",
        "                update_bounds(edge[\"start\"])\n",
        "                update_bounds(edge[\"end\"])\n",
        "            elif etype == 'ARC':\n",
        "                arc_edges, arc_meta = parse_arc(entity, min_segments=config.get(\"arc_segments_per_180\", 8), max_segments=64, config=config)\n",
        "                all_edges.extend(e for e in arc_edges if is_valid_edge(e))\n",
        "                for e in arc_edges:\n",
        "                    update_bounds(e[\"start\"])\n",
        "                    update_bounds(e[\"end\"])\n",
        "                geometry[\"arcs\"].append(arc_meta)\n",
        "            elif etype == 'CIRCLE':\n",
        "                center = list(entity.dxf.center)\n",
        "                radius = entity.dxf.radius\n",
        "                geometry[\"circles\"].append({\n",
        "                    \"center\": center,\n",
        "                    \"radius\": radius,\n",
        "                    \"layer\": layer\n",
        "                })\n",
        "                update_bounds([center[0] - radius, center[1] - radius])\n",
        "                update_bounds([center[0] + radius, center[1] + radius])\n",
        "            elif etype == 'LWPOLYLINE':\n",
        "                segments = parse_lwpolyline(entity)\n",
        "                all_edges.extend(e for e in segments if is_valid_edge(e))\n",
        "                for e in segments:\n",
        "                    update_bounds(e[\"start\"])\n",
        "                    update_bounds(e[\"end\"])\n",
        "            elif etype == 'POLYLINE':\n",
        "                segments = parse_polyline(entity)\n",
        "                all_edges.extend(e for e in segments if is_valid_edge(e))\n",
        "                for e in segments:\n",
        "                    update_bounds(e[\"start\"])\n",
        "                    update_bounds(e[\"end\"])\n",
        "            elif etype == 'SPLINE':\n",
        "                segments = parse_spline(entity)\n",
        "                all_edges.extend(e for e in segments if is_valid_edge(e))\n",
        "                for e in segments:\n",
        "                    update_bounds(e[\"start\"])\n",
        "                    update_bounds(e[\"end\"])\n",
        "            elif etype == 'TEXT':\n",
        "                try:\n",
        "                    txt = entity.dxf.text.strip()\n",
        "                    pos = list(entity.dxf.insert)\n",
        "                    role = match_text_to_role(txt)\n",
        "\n",
        "                    geometry[\"texts\"].append({\n",
        "                        \"text\": txt,\n",
        "                        \"insert\": pos,\n",
        "                        \"rotation\": entity.dxf.rotation,\n",
        "                        \"height\": entity.dxf.height,\n",
        "                        \"layer\": layer\n",
        "                    })\n",
        "                    if role:\n",
        "                        geometry.setdefault(\"semantic_tags\", []).append({\n",
        "                            \"text\": txt,\n",
        "                            \"position\": pos,\n",
        "                            \"layer\": layer,\n",
        "                            \"role\": role\n",
        "                        })\n",
        "                except Exception as e:\n",
        "                    warnings.append(f\"TEXT parse error: {str(e)}\")\n",
        "            elif etype == 'DIMENSION':\n",
        "                try:\n",
        "                    txt = entity.dxf.text.strip()\n",
        "                    pos = list(entity.dxf.defpoint)\n",
        "                    role = match_text_to_role(txt)\n",
        "                    geometry[\"dimensions\"].append({\n",
        "                        \"text\": txt,\n",
        "                        \"insert\": pos,\n",
        "                        \"layer\": layer,\n",
        "                        \"role\": role\n",
        "                    })\n",
        "                    if role:\n",
        "                        geometry.setdefault(\"semantic_tags\", []).append({\n",
        "                            \"text\": txt,\n",
        "                            \"position\": pos,\n",
        "                            \"layer\": layer,\n",
        "                            \"role\": role\n",
        "                        })\n",
        "                except Exception as e:\n",
        "                    warnings.append(f\"DIMENSION parse error: {str(e)}\")\n",
        "            elif etype == 'HATCH':\n",
        "                try:\n",
        "                    for path in entity.paths:\n",
        "                        edges = []\n",
        "                        if path.has_edges:\n",
        "                            for edge in path.edges:\n",
        "                                if edge.TYPE == 'LineEdge':\n",
        "                                    e = {\n",
        "                                        \"type\": \"line\",\n",
        "                                        \"start\": list(edge.start),\n",
        "                                        \"end\": list(edge.end),\n",
        "                                        \"layer\": layer,\n",
        "                                        \"source\": \"hatch\"\n",
        "                                    }\n",
        "                                    edges.append(e)\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                                elif edge.TYPE == 'ArcEdge':\n",
        "                                    arc = {\n",
        "                                        \"center\": list(edge.center),\n",
        "                                        \"radius\": edge.radius,\n",
        "                                        \"start_angle\": edge.start_angle,\n",
        "                                        \"end_angle\": edge.end_angle,\n",
        "                                        \"layer\": layer\n",
        "                                    }\n",
        "                                    arc_segs = arc_to_edges(arc)\n",
        "                                    edges.extend(arc_segs)\n",
        "                                    for e in arc_segs:\n",
        "                                        update_bounds(e[\"start\"])\n",
        "                                        update_bounds(e[\"end\"])\n",
        "                                else:\n",
        "                                    warnings.append(f\"HATCH unsupported edge type: {edge.TYPE}\")\n",
        "                        elif path.path_type_flags & 2:\n",
        "                            pts = [[v[0], v[1], 0] for v in path.vertices]\n",
        "                            for i in range(len(pts) - 1):\n",
        "                                e = {\"type\": \"line\", \"start\": pts[i], \"end\": pts[i + 1], \"layer\": layer}\n",
        "                                edges.append(e)\n",
        "                                update_bounds(e[\"start\"])\n",
        "                                update_bounds(e[\"end\"])\n",
        "                            if path.has_closed_path:\n",
        "                                e = {\"type\": \"line\", \"start\": pts[-1], \"end\": pts[0], \"layer\": layer}\n",
        "                                edges.append(e)\n",
        "                                update_bounds(e[\"start\"])\n",
        "                                update_bounds(e[\"end\"])\n",
        "                        else:\n",
        "                            warnings.append(f\"HATCH path skipped: unsupported path structure\")\n",
        "                        all_edges.extend(e for e in edges if is_valid_edge(e))\n",
        "                        geometry[\"hatch_boundaries\"].append([e[\"start\"] for e in edges])\n",
        "                except Exception as e:\n",
        "                    warnings.append(f\"HATCH parse error: {str(e)}\")\n",
        "            elif etype == 'REGION':\n",
        "                try:\n",
        "                    exploded = list(entity.explode())\n",
        "                    for sub_entity in exploded:\n",
        "                        try:\n",
        "                            sub_etype = sub_entity.dxftype()\n",
        "                            if sub_etype == 'LINE':\n",
        "                                e = parse_line(sub_entity)\n",
        "                                if is_valid_edge(e):\n",
        "                                    all_edges.append(e)\n",
        "                                update_bounds(e[\"start\"])\n",
        "                                update_bounds(e[\"end\"])\n",
        "                            elif sub_etype == 'ARC':\n",
        "                                arc_edges, arc_meta = parse_arc(sub_entity, min_segments=config.get(\"arc_segments_per_180\", 8), max_segments=64, config=config)\n",
        "                                all_edges.extend(e for e in arc_edges if is_valid_edge(e))\n",
        "                                for e in arc_edges:\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                                geometry[\"arcs\"].append(arc_meta)\n",
        "                            elif sub_etype == 'ELLIPSE':\n",
        "                                ellipse_meta = {\n",
        "                                    \"center\": list(sub_entity.dxf.center),\n",
        "                                    \"major_axis\": list(sub_entity.dxf.major_axis),\n",
        "                                    \"ratio\": sub_entity.dxf.ratio,\n",
        "                                    \"start_param\": sub_entity.dxf.start_param,\n",
        "                                    \"end_param\": sub_entity.dxf.end_param,\n",
        "                                    \"layer\": sub_entity.dxf.layer\n",
        "                                }\n",
        "                                geometry[\"ellipses\"].append(ellipse_meta)\n",
        "                                approx_pts = list(sub_entity.flattening(distance=0.5))\n",
        "                                for i in range(len(approx_pts) - 1):\n",
        "                                    e = {\n",
        "                                        \"type\": \"line\",\n",
        "                                        \"start\": list(approx_pts[i]),\n",
        "                                        \"end\": list(approx_pts[i + 1]),\n",
        "                                        \"layer\": sub_entity.dxf.layer,\n",
        "                                        \"source\": \"region_ellipse\"\n",
        "                                    }\n",
        "                                    if is_valid_edge(e):\n",
        "                                        all_edges.append(e)\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                            else:\n",
        "                                warnings.append(f\"REGION exploded entity unsupported: {sub_etype}\")\n",
        "                        except Exception as e:\n",
        "                            warnings.append(f\"REGION sub-entity error: {str(e)}\")\n",
        "                except Exception as e:\n",
        "                    warnings.append(f\"REGION explode failed: {str(e)}\")\n",
        "            elif etype == 'INSERT':\n",
        "                try:\n",
        "                    exploded = entity.explode()\n",
        "                    for sub_entity in exploded:\n",
        "                        try:\n",
        "                            sub_etype = sub_entity.dxftype()\n",
        "                            sub_layer = sub_entity.dxf.layer\n",
        "                            if layer_config:\n",
        "                                if \"allowed_layers\" in layer_config and sub_layer not in layer_config[\"allowed_layers\"]:\n",
        "                                    continue\n",
        "                                if \"ignored_layers\" in layer_config and sub_layer in layer_config[\"ignored_layers\"]:\n",
        "                                    continue\n",
        "                            if sub_etype == 'LINE':\n",
        "                                e = parse_line(sub_entity)\n",
        "                                if is_valid_edge(e):\n",
        "                                    all_edges.append(e)\n",
        "                                update_bounds(e[\"start\"])\n",
        "                                update_bounds(e[\"end\"])\n",
        "                            elif sub_etype == 'ARC':\n",
        "                                arc_edges, arc_meta = parse_arc(sub_entity, min_segments=config.get(\"arc_segments_per_180\", 8), max_segments=64, config=config)\n",
        "                                all_edges.extend(e for e in arc_edges if is_valid_edge(e))\n",
        "                                for e in arc_edges:\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                                geometry[\"arcs\"].append(arc_meta)\n",
        "                            elif sub_etype == 'CIRCLE':\n",
        "                                center = list(sub_entity.dxf.center)\n",
        "                                radius = sub_entity.dxf.radius\n",
        "                                geometry[\"circles\"].append({\n",
        "                                    \"center\": center,\n",
        "                                    \"radius\": radius,\n",
        "                                    \"layer\": sub_layer\n",
        "                                })\n",
        "                                update_bounds([center[0] - radius, center[1] - radius])\n",
        "                                update_bounds([center[0] + radius, center[1] + radius])\n",
        "                            elif sub_etype == 'LWPOLYLINE':\n",
        "                                segments = parse_lwpolyline(sub_entity)\n",
        "                                all_edges.extend(e for e in segments if is_valid_edge(e))\n",
        "                                for e in segments:\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                            elif sub_etype == 'POLYLINE':\n",
        "                                segments = parse_polyline(sub_entity)\n",
        "                                all_edges.extend(e for e in segments if is_valid_edge(e))\n",
        "                                for e in segments:\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                            elif sub_etype == 'SPLINE':\n",
        "                                segments = parse_spline(sub_entity)\n",
        "                                all_edges.extend(e for e in segments if is_valid_edge(e))\n",
        "                                for e in segments:\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                            elif sub_etype == 'ELLIPSE':\n",
        "                                ellipse_meta = {\n",
        "                                    \"center\": list(sub_entity.dxf.center),\n",
        "                                    \"major_axis\": list(sub_entity.dxf.major_axis),\n",
        "                                    \"ratio\": sub_entity.dxf.ratio,\n",
        "                                    \"start_param\": sub_entity.dxf.start_param,\n",
        "                                    \"end_param\": sub_entity.dxf.end_param,\n",
        "                                    \"layer\": sub_layer\n",
        "                                }\n",
        "                                geometry.setdefault(\"ellipses\", []).append(ellipse_meta)\n",
        "                                approx_pts = list(sub_entity.flattening(distance=0.5))\n",
        "                                for i in range(len(approx_pts) - 1):\n",
        "                                    e = {\n",
        "                                        \"type\": \"line\",\n",
        "                                        \"start\": list(approx_pts[i]),\n",
        "                                        \"end\": list(approx_pts[i + 1]),\n",
        "                                        \"layer\": sub_layer,\n",
        "                                        \"source\": \"insert_ellipse\"\n",
        "                                    }\n",
        "                                    if is_valid_edge(e):\n",
        "                                        all_edges.append(e)\n",
        "                                    update_bounds(e[\"start\"])\n",
        "                                    update_bounds(e[\"end\"])\n",
        "                            else:\n",
        "                                warnings.append(f\"INSERT exploded sub-entity unsupported: {sub_etype}\")\n",
        "                        except Exception as e:\n",
        "                            warnings.append(f\"INSERT sub-entity error: {str(e)}\")\n",
        "                except Exception as e:\n",
        "                    warnings.append(f\"INSERT explode failed: {str(e)}\")\n",
        "            else:\n",
        "                warnings.append(f\"Skipped unsupported entity: {etype}\")\n",
        "        except Exception as e:\n",
        "            warnings.append(f\"{entity.dxftype()} parse error: {str(e)}\")\n",
        "            # The function processes all DXF entity types: LINE, ARC, CIRCLE, SPLINE, etc.\n",
        "            # And updates `all_edges`, `geometry`, and `warnings` accordingly.\n",
        "\n",
        "    # Adaptive tolerance (optional)\n",
        "    if config and config.get(\"adaptive_tolerance\", False) and tolerance is None:\n",
        "        bbox_width = bbox_max[0] - bbox_min[0]\n",
        "        bbox_height = bbox_max[1] - bbox_min[1]\n",
        "        bbox_diagonal = math.sqrt(bbox_width**2 + bbox_height**2)\n",
        "        adaptive_tol = 0.001 * bbox_diagonal\n",
        "        max_tolerance = config.get(\"max_tolerance\", 1.0)\n",
        "        tolerance = min(adaptive_tol, max_tolerance)\n",
        "        min_tolerance = config.get(\"min_tolerance\", 0.001)\n",
        "        tolerance = max(tolerance, min_tolerance)\n",
        "        warnings.append(f\"Adaptive tolerance computed: {tolerance:.6f}\")\n",
        "\n",
        "    # Build chains and extract holes/profiles\n",
        "    chains = build_chains(all_edges, tol=tolerance)\n",
        "    cutout_counts = detect_cutouts(chains, geometry.get(\"circles\", []))\n",
        "    classify_profiles(chains, geometry=geometry)\n",
        "\n",
        "    # Identify hole candidates (circular or revolution chains)\n",
        "    geometry[\"hole_candidates\"] = []\n",
        "    for i, circ in enumerate(geometry.get(\"circles\", [])):\n",
        "        if circ[\"radius\"] < 30:\n",
        "            circ[\"hole\"] = True\n",
        "            geometry[\"hole_candidates\"].append({\"type\": \"circle\", \"index\": i})\n",
        "    for i, chain in enumerate(chains):\n",
        "        if chain.get(\"is_closed\") and chain.get(\"type\") == \"revolution\":\n",
        "            chain[\"hole\"] = True\n",
        "            geometry[\"hole_candidates\"].append({\"type\": \"chain\", \"index\": i})\n",
        "\n",
        "    # Classify actual holes\n",
        "    geometry[\"holes\"] = []\n",
        "    hole_radius_thresh = config.get(\"hole_radius_threshold\", 20.0) if config else 20.0\n",
        "    bolt_keywords = {\"anker\", \"bolt\", \"loch\", \"bohr\", \"m\", \"sw\"}\n",
        "\n",
        "    for circle in geometry.get(\"circles\", []):\n",
        "        center, radius, layer = circle[\"center\"], circle[\"radius\"], circle[\"layer\"]\n",
        "        if radius < hole_radius_thresh:\n",
        "            role = None\n",
        "            nearby_tags = [\n",
        "                tag for tag in geometry.get(\"semantic_tags\", [])\n",
        "                if ((tag[\"position\"][0] - center[0])**2 + (tag[\"position\"][1] - center[1])**2)**0.5 < 15\n",
        "            ]\n",
        "            for tag in nearby_tags:\n",
        "                txt = tag[\"text\"].lower()\n",
        "                if any(k in txt for k in bolt_keywords):\n",
        "                    role = \"bolt_hole\"\n",
        "                    break\n",
        "            if not role:\n",
        "                role = \"generic_hole\"\n",
        "            geometry[\"holes\"].append({\n",
        "                \"center\": center,\n",
        "                \"radius\": radius,\n",
        "                \"layer\": layer,\n",
        "                \"role\": role,\n",
        "                \"type\": \"circular\",\n",
        "                \"source\": \"circle\"\n",
        "            })\n",
        "\n",
        "    for i, chain in enumerate(chains):\n",
        "        if chain.get(\"hole\") and chain.get(\"centroid\") and chain.get(\"points\"):\n",
        "            center = chain[\"centroid\"]\n",
        "            points = chain[\"points\"]\n",
        "            approx_radius = sum(\n",
        "                ((p[0] - center[0])**2 + (p[1] - center[1])**2)**0.5 for p in points\n",
        "            ) / len(points)\n",
        "            geometry[\"holes\"].append({\n",
        "                \"center\": center,\n",
        "                \"radius\": approx_radius,\n",
        "                \"role\": \"generic_hole\",\n",
        "                \"type\": \"circular\",\n",
        "                \"source\": \"chain\",\n",
        "                \"chain_index\": i\n",
        "            })\n",
        "\n",
        "    # Final aggregation\n",
        "    geometry[\"edges\"] = all_edges\n",
        "    geometry[\"edge_chains\"] = chains\n",
        "    group_features(geometry)\n",
        "\n",
        "    # Check planarity\n",
        "    z_vals = [p[2] for e in all_edges for p in (e[\"start\"], e[\"end\"]) if len(p) == 3]\n",
        "    if z_vals:\n",
        "        min_z, max_z = min(z_vals), max(z_vals)\n",
        "        if abs(max_z - min_z) > 1e-3:\n",
        "            warnings.append(f\"Non-planar geometry detected: Z range = {min_z:.3f} to {max_z:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"filename\": os.path.basename(filepath),\n",
        "        \"drawing_units\": units,\n",
        "        \"tolerance_used\": tolerance,\n",
        "        \"geometry\": dict(geometry),\n",
        "        \"stats\": {\n",
        "            \"edge_count\": len(all_edges),\n",
        "            \"degenerate_edges\": 0,\n",
        "            \"chain_count\": len(chains),\n",
        "            \"open_chains\": sum(not c[\"is_closed\"] for c in chains),\n",
        "            \"cutouts\": sum(c[\"is_cutout\"] for c in chains),\n",
        "            \"revolutions\": sum(c[\"type\"] == \"revolution\" for c in chains),\n",
        "            \"extrusions\": sum(c[\"type\"] == \"extrusion\" for c in chains),\n",
        "            \"unit\": units\n",
        "        },\n",
        "        \"warnings\": warnings\n",
        "    }\n"
      ],
      "metadata": {
        "id": "i0cF_uqVX3Xe"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G. Batch Processing & Layer Summary\n",
        "Process folders of DXFs and summarize layers.\n"
      ],
      "metadata": {
        "id": "HGWj2VmsZGvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_folder(folder_path, output_path, tolerance=0.1):\n",
        "    \"\"\"\n",
        "    Parse all DXF files in a folder and export their geometry as JSON.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to input folder containing .dxf files.\n",
        "        output_path (str): Path to folder where parsed .json outputs will be saved.\n",
        "        tolerance (float): Tolerance value for edge joining (if not using adaptive).\n",
        "\n",
        "    Behavior:\n",
        "        - Loads optional `config.json` from the folder for parsing settings.\n",
        "        - Applies layer filtering and adaptive tolerance if specified.\n",
        "        - Runs `parse_dxf_entities` for each file and writes results to output.\n",
        "        - Prints a brief summary per file.\n",
        "    \"\"\"\n",
        "    folder = Path(folder_path)\n",
        "    output = Path(output_path)\n",
        "    output.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load optional configuration\n",
        "    config_path = folder / \"config.json\"\n",
        "    config = {}\n",
        "    if config_path.exists():\n",
        "        try:\n",
        "            with open(config_path) as f:\n",
        "                config = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load config.json: {e}\")\n",
        "            config = {}\n",
        "\n",
        "    # Extract layer filtering config\n",
        "    layer_config = {\n",
        "        \"allowed_layers\": config.get(\"allowed_layers\"),\n",
        "        \"ignored_layers\": config.get(\"ignored_layers\")\n",
        "    }\n",
        "    use_adaptive = config.get(\"adaptive_tolerance\", False)\n",
        "\n",
        "    # Process each DXF file in folder\n",
        "    for file in folder.glob(\"*.dxf\"):\n",
        "        tol = None if use_adaptive else tolerance\n",
        "        result = parse_dxf_entities(\n",
        "            str(file),\n",
        "            tolerance=tol,\n",
        "            layer_config=layer_config,\n",
        "            config=config\n",
        "        )\n",
        "\n",
        "        geometry = result[\"geometry\"]\n",
        "        chains = geometry.get(\"edge_chains\", [])\n",
        "        circles = geometry.get(\"circles\", [])\n",
        "        geometry[\"chains\"] = chains  # Alias for convenience\n",
        "\n",
        "        # Recompute cutout stats\n",
        "        cutout_counts = detect_cutouts(chains, circles)\n",
        "        result[\"stats\"][\"cutouts\"] = (\n",
        "            f\"{cutout_counts['chains']} chains + {cutout_counts['circles']} circles = \"\n",
        "            f\"{cutout_counts['chains'] + cutout_counts['circles']}\"\n",
        "        )\n",
        "\n",
        "        # Save JSON output\n",
        "        outname = output / f\"{file.stem}_geometry.json\"\n",
        "        with open(outname, \"w\") as f:\n",
        "            json.dump(result, f, indent=2)\n",
        "\n",
        "        # Print summary\n",
        "        stats = result[\"stats\"]\n",
        "        print(f\" {file.name}\")\n",
        "        print(f\"    Chains: {stats['chain_count']},  Repaired: {sum(c.get('repaired') for c in chains)}\")\n",
        "        print(f\"    Cutouts: {stats['cutouts']}\")\n",
        "        print(f\"    Edges: {stats['edge_count']}\")\n",
        "\n",
        "        arcs = geometry.get('arcs', [])\n",
        "        if arcs:\n",
        "            max_radius = max(a[\"radius\"] for a in arcs)\n",
        "            print(f\"    Arcs: {len(arcs)} (Max Radius: {max_radius:.2f})\")\n",
        "\n",
        "        if result[\"warnings\"]:\n",
        "            print(f\"    {len(result['warnings'])} warnings\")\n",
        "        print()\n",
        "\n",
        "\n",
        "def collect_layer_summary(folder_path):\n",
        "    \"\"\"\n",
        "    Analyze all DXF files in a folder and summarize layer usage.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to folder containing .dxf files.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - dict with layer name -> total count across files\n",
        "            - dict with filename -> set of layers used in that file\n",
        "    \"\"\"\n",
        "    folder = Path(folder_path)\n",
        "    layer_counts = Counter()\n",
        "    file_layers = defaultdict(set)\n",
        "\n",
        "    for file in folder.glob(\"*.dxf\"):\n",
        "        try:\n",
        "            doc = ezdxf.readfile(file)\n",
        "            msp = doc.modelspace()\n",
        "\n",
        "            for entity in msp:\n",
        "                layer = entity.dxf.layer\n",
        "                layer_counts[layer] += 1\n",
        "                file_layers[file.name].add(layer)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Could not read {file.name}: {e}\")\n",
        "\n",
        "    return dict(layer_counts), dict(file_layers)\n"
      ],
      "metadata": {
        "id": "EhTsK5tZZIwp"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### H. Metadata Tagging\n",
        "Link TEXT annotations in the drawing to roles (e.g. axis, centerline).\n"
      ],
      "metadata": {
        "id": "m00anKkRZxso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_text_to_role(text):\n",
        "    \"\"\"\n",
        "    Classify a DXF TEXT annotation into a semantic role based on keywords or patterns.\n",
        "\n",
        "    Args:\n",
        "        text (str): The raw text string from the DXF entity.\n",
        "\n",
        "    Returns:\n",
        "        str or None: A role string (e.g., 'bolt_height', 'thread_size') or None if unmatched.\n",
        "    \"\"\"\n",
        "    text_norm = text.strip().lower()\n",
        "\n",
        "    # Direct keyword mapping\n",
        "    keyword_map = {\n",
        "        \"ankerhöhe\": \"bolt_height\",\n",
        "        \"rohlänge\": \"raw_length\",\n",
        "        \"bolzenrohlänge\": \"raw_length\",\n",
        "        \"bolzen-\": \"bolt_prefix\",\n",
        "        \"gesamthöhe\": \"total_height\",\n",
        "        \"sw\": \"wrench_size\",\n",
        "        \"= prüfmaß\": \"inspection_flag\",\n",
        "        \"= funktionsrelevantes merkmal\": \"functional_flag\",\n",
        "        \"prüfung erfolgt mit prüflehre\": \"inspection_note\",\n",
        "        \"prägestempel wechseln\": \"stamp_change_note\",\n",
        "        \"achtung!\": \"warning_note\",\n",
        "    }\n",
        "\n",
        "    for key, role in keyword_map.items():\n",
        "        if text_norm.startswith(key) or text_norm == key:\n",
        "            return role\n",
        "\n",
        "    # Pattern-based matching\n",
        "    regex_map = {\n",
        "        r\"^m\\d{1,2}$\": \"thread_size\",             # e.g. \"M6\", \"M12\"\n",
        "        r\"^%%c\\d+$\": \"symbol_code\",               # e.g. DXF special character codes\n",
        "        r\"^hta\\s*-\\s*ce.*\": \"part_id\",            # e.g. \"HTA - CE1234\"\n",
        "        r\"^\\d+$\": \"numeric_note\",                 # Just a number\n",
        "        r\"^\\*+$\": \"asterisk_marker\",              # A string of one or more asterisks\n",
        "    }\n",
        "\n",
        "    for pattern, role in regex_map.items():\n",
        "        if re.fullmatch(pattern, text_norm):\n",
        "            return role\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "JT29N0CxZxiY"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. File Paths\n",
        "Specify the source folder for DXF files and the destination for parsed geometry output.\n"
      ],
      "metadata": {
        "id": "uV_CqhNZQXVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output paths\n",
        "dxf_folder = Path()\n",
        "output_folder = Path()\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_folder.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "s1LfYsNMQX-g"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Configuration Setup\n",
        "\n",
        "Configure how the parser interprets geometry:\n",
        "- Set which DXF layers to include or ignore.\n",
        "- Enable adaptive tolerance to automatically adjust based on drawing size.\n",
        "- Define arc segmentation granularity (segments per 180 degrees).\n"
      ],
      "metadata": {
        "id": "JtNZRWavcI63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect available layers in the folder\n",
        "layer_counts, _ = collect_layer_summary(dxf_folder)\n",
        "\n",
        "# Define configuration parameters\n",
        "config = {\n",
        "    \"allowed_layers\": sorted(layer_counts.keys()),  # include all layers by default\n",
        "    \"ignored_layers\": [],                           # or selectively ignore some\n",
        "    \"adaptive_tolerance\": True,                     # auto-adjust tolerance based on bounding box\n",
        "    \"max_tolerance\": 1.0,                           # upper limit for adaptive tolerance\n",
        "    \"arc_segments_per_180\": 20                      # resolution of arc approximation\n",
        "}\n",
        "\n",
        "# Save config to the same folder as the DXFs\n",
        "config_path = dxf_folder / \"config.json\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n"
      ],
      "metadata": {
        "id": "4bewER_pb_72"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Execute Parser\n",
        "\n",
        "Run the parser on all DXF files in the specified folder.\n",
        "This will extract and process the geometry, then save structured JSON files to the output directory.\n"
      ],
      "metadata": {
        "id": "EmbUxKqKeesm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run batch parser on all DXFs in the input folder\n",
        "parse_folder(dxf_folder, output_folder)"
      ],
      "metadata": {
        "id": "Sqz0FdakeBZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Final Notes\n",
        "\n",
        "This notebook is part of a **four-step modular pipeline** for extracting and validating BIM-ready geometry from structural engineering drawings.\n",
        "\n",
        "### Output Location\n",
        "- Parsed geometry is saved as `_geometry.json` files in the defined `output_folder`.\n",
        "\n",
        "### How to Run\n",
        "1. Set your `dxf_folder` and `output_folder` paths in **Section 3**.\n",
        "2. Ensure all dependencies are installed (e.g., `ezdxf`, `matplotlib`, `numpy`).\n",
        "3. Run all cells from top to bottom.\n",
        "\n",
        "### Next Step\n",
        "- Continue to the next notebook: `[Geometry Interpreter]`\n",
        "\n",
        "### Documentation\n",
        "For full setup instructions and pipeline details, see the [README.md](https://github.com/yourusername/thesis-geometry-pipeline) in the repository.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VAh3wfMaaoZP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}