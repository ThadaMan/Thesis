{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Validator Module – Structural Geometry Pipeline  \n",
        "**Author**: Thaddeus da Silva Correa  \n",
        "**Project**: Automated Extraction and Interpretation of Structural Geometry from CAD Drawings for BIM Integration  \n",
        "**Module**: 4 of 4 – Validator  \n",
        "**Environment**: Google Colab  \n",
        "**Last updated**: June 2025\n",
        "\n",
        "---\n",
        "\n",
        "This module validates the structured output generated by the **JSON Builder**. It checks if the resulting BIM data adheres to the expected format and structural correctness. The validator performs checks on the geometry, ensuring that the shapes are correctly classified, the labels match expectations, and the output adheres to the BIM schema.\n",
        "\n",
        "**Inputs**: Structured parts data in JSON format (produced by the JSON Builder)  \n",
        "**Outputs**: Validated parts definitions in JSON format, including error/warning messages if the output is invalid or inconsistent\n"
      ],
      "metadata": {
        "id": "jvGKs2aBNqag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup  \n",
        "Import required libraries and define the validation schema for structured BIM JSON files.\n"
      ],
      "metadata": {
        "id": "EY9s6LJ3NtgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import jsonschema\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "# JSON Schema used to validate the BIM section of the structured output\n",
        "STRUCTURED_OUTPUT_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"bim\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"insertion_points\": {\"type\": \"object\"},\n",
        "                \"chaining_point\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"is_insertion_point\": {\"type\": \"boolean\"},\n",
        "                        \"origin\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"x\": {\"type\": \"number\"},\n",
        "                                \"y\": {\"type\": \"number\"},\n",
        "                                \"z\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"x\", \"y\", \"z\"]\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"is_insertion_point\", \"origin\"]\n",
        "                },\n",
        "                \"measurement_points\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"x\": {\"type\": \"number\"},\n",
        "                            \"y\": {\"type\": \"number\"},\n",
        "                            \"z\": {\"type\": \"number\"}\n",
        "                        },\n",
        "                        \"required\": [\"x\", \"y\", \"z\"]\n",
        "                    }\n",
        "                },\n",
        "                \"parts\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"shape\": {\"type\": \"string\"},\n",
        "                            \"origin\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"properties\": {\n",
        "                                    \"x\": {\"type\": \"number\"},\n",
        "                                    \"y\": {\"type\": \"number\"},\n",
        "                                    \"z\": {\"type\": \"number\"},\n",
        "                                    \"rotation\": {\n",
        "                                        \"type\": \"array\",\n",
        "                                        \"items\": {\"type\": \"number\"},\n",
        "                                        \"minItems\": 3,\n",
        "                                        \"maxItems\": 3\n",
        "                                    }\n",
        "                                },\n",
        "                                \"required\": [\"x\", \"y\", \"z\"]\n",
        "                            },\n",
        "                            \"profile\": {\n",
        "                                \"type\": \"array\",\n",
        "                                \"items\": {\n",
        "                                    \"type\": \"object\",\n",
        "                                    \"properties\": {\n",
        "                                        \"x\": {\"type\": \"number\"},\n",
        "                                        \"y\": {\"type\": \"number\"},\n",
        "                                        \"z\": {\"type\": \"number\"},\n",
        "                                        \"type\": {\"type\": \"string\"}\n",
        "                                    },\n",
        "                                    \"required\": [\"x\", \"y\", \"z\", \"type\"]\n",
        "                                }\n",
        "                            },\n",
        "                            \"cutout\": {\n",
        "                                \"type\": \"array\",\n",
        "                                \"items\": {\"type\": \"object\"}\n",
        "                            },\n",
        "                            \"bounding_box\": {\"type\": \"object\"}\n",
        "                        },\n",
        "                        \"required\": [\"shape\"]\n",
        "                    }\n",
        "                },\n",
        "                \"classification\": {\"type\": \"object\"},\n",
        "                \"insertion_box\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"shape\": {\"type\": \"string\"},\n",
        "                        \"min_point\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"x\": {\"type\": \"number\"},\n",
        "                                \"y\": {\"type\": \"number\"},\n",
        "                                \"z\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"x\", \"y\", \"z\"]\n",
        "                        },\n",
        "                        \"max_point\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"x\": {\"type\": \"number\"},\n",
        "                                \"y\": {\"type\": \"number\"},\n",
        "                                \"z\": {\"type\": \"number\"}\n",
        "                            },\n",
        "                            \"required\": [\"x\", \"y\", \"z\"]\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"shape\", \"min_point\", \"max_point\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"parts\", \"insertion_box\"]\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"bim\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "S4iPuZq0N1d4"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Core Validation Functions  \n",
        "In this section, we define the core functions used to validate structured geometry output. These functions are organized into the following categories:\n",
        "\n",
        "** A. I/O and Distance Utilities**  \n",
        "** B. Bounding Box and Volume Calculations**  \n",
        "** C. Part Feature Checks**  \n",
        "** D. Schema Validators**  \n",
        "** E. Batch Validation Logic**  \n",
        "\n"
      ],
      "metadata": {
        "id": "KJ1LDyfvN2NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. I/O and Distance Utilities  \n",
        "Helper functions for loading structured JSON files and calculating basic geometric distances.\n"
      ],
      "metadata": {
        "id": "425UrbtkEJmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json(filepath: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Load a JSON file from the given filepath.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        dict: Parsed JSON data.\n",
        "    \"\"\"\n",
        "    with open(filepath, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def euclidean_distance_3d(p1: Dict, p2: Dict) -> float:\n",
        "    \"\"\"\n",
        "    Compute Euclidean distance between two 3D points.\n",
        "\n",
        "    Args:\n",
        "        p1 (dict): First point with 'x', 'y', 'z' keys.\n",
        "        p2 (dict): Second point with 'x', 'y', 'z' keys.\n",
        "\n",
        "    Returns:\n",
        "        float: Euclidean distance between p1 and p2.\n",
        "    \"\"\"\n",
        "    return math.sqrt(\n",
        "        (p1[\"x\"] - p2[\"x\"])**2 +\n",
        "        (p1[\"y\"] - p2[\"y\"])**2 +\n",
        "        (p1[\"z\"] - p2[\"z\"])**2\n",
        "    )\n",
        "\n",
        "\n",
        "def mean_profile_distance(p1: Dict, p2: Dict) -> float:\n",
        "    \"\"\"\n",
        "    Compute the mean distance between corresponding vertices of two profiles.\n",
        "\n",
        "    Args:\n",
        "        p1 (dict): First part with a 'profile' key containing 'vertices'.\n",
        "        p2 (dict): Second part with a 'profile' key containing 'vertices'.\n",
        "\n",
        "    Returns:\n",
        "        float: Mean distance between corresponding 2D vertices, or None if invalid.\n",
        "    \"\"\"\n",
        "    v1 = p1.get(\"profile\", {}).get(\"vertices\", [])\n",
        "    v2 = p2.get(\"profile\", {}).get(\"vertices\", [])\n",
        "    if len(v1) != len(v2) or not v1:\n",
        "        return None\n",
        "    return sum(\n",
        "        math.sqrt((a[\"x\"] - b[\"x\"])**2 + (a[\"y\"] - b[\"y\"])**2)\n",
        "        for a, b in zip(v1, v2)\n",
        "    ) / len(v1)\n"
      ],
      "metadata": {
        "id": "ACGD4pjZEOH9"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Bounding Box and Volume  \n",
        "Functions to compute approximate bounding boxes and intersection-over-union (IoU) for part comparison.\n"
      ],
      "metadata": {
        "id": "pg4rZLVkEV-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bounding_box(part: Dict) -> (Dict, Dict):\n",
        "    \"\"\"\n",
        "    Extract the 3D bounding box for a given part, based on its shape type.\n",
        "\n",
        "    Supports:\n",
        "    - 'cuboid': uses provided min/max points\n",
        "    - 'extrusion': projects profile vertices along extrusion path\n",
        "    - 'revolution': approximates full 360 sweep to generate boundary points\n",
        "\n",
        "    Args:\n",
        "        part (dict): Part dictionary from structured output.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (min_point, max_point) each a dict with 'x', 'y', 'z' keys.\n",
        "               Returns (None, None) if bounding box can't be computed.\n",
        "    \"\"\"\n",
        "    shape = part.get(\"shape\")\n",
        "\n",
        "    if shape == \"cuboid\":\n",
        "        return part.get(\"min_point\"), part.get(\"max_point\")\n",
        "\n",
        "    elif shape == \"extrusion\":\n",
        "        profile = part.get(\"profile\", {}).get(\"vertices\", [])\n",
        "        path = part.get(\"path\", {})\n",
        "        if not profile or not path:\n",
        "            return None, None\n",
        "\n",
        "        dx, dy, dz = path.get(\"x\", 0), path.get(\"y\", 0), path.get(\"z\", 0)\n",
        "        points = []\n",
        "        for v in profile:\n",
        "            points.append(v)\n",
        "            points.append({\n",
        "                \"x\": v[\"x\"] + dx,\n",
        "                \"y\": v[\"y\"] + dy,\n",
        "                \"z\": v[\"z\"] + dz,\n",
        "            })\n",
        "\n",
        "    elif shape == \"revolution\":\n",
        "        profile = part.get(\"profile\", {}).get(\"vertices\", [])\n",
        "        axis_origin = part.get(\"axis_origin\", {})\n",
        "        if not profile or not axis_origin:\n",
        "            return None, None\n",
        "\n",
        "        points = []\n",
        "        for v in profile:\n",
        "            r = ((v[\"x\"] - axis_origin[\"x\"])**2 + (v[\"y\"] - axis_origin[\"y\"])**2) ** 0.5\n",
        "            z = v[\"z\"]\n",
        "            for theta in [0, 90, 180, 270]:  # Sample 4 quadrants\n",
        "                rad = math.radians(theta)\n",
        "                points.append({\n",
        "                    \"x\": axis_origin[\"x\"] + r * math.cos(rad),\n",
        "                    \"y\": axis_origin[\"y\"] + r * math.sin(rad),\n",
        "                    \"z\": z\n",
        "                })\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "    # Compute axis-aligned bounding box\n",
        "    xs = [p[\"x\"] for p in points]\n",
        "    ys = [p[\"y\"] for p in points]\n",
        "    zs = [p[\"z\"] for p in points]\n",
        "    return {\n",
        "        \"x\": min(xs), \"y\": min(ys), \"z\": min(zs)\n",
        "    }, {\n",
        "        \"x\": max(xs), \"y\": max(ys), \"z\": max(zs)\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_bounding_box_iou(part_a: Dict, part_b: Dict) -> float:\n",
        "    \"\"\"\n",
        "    Compute the intersection-over-union (IoU) of the bounding boxes of two parts.\n",
        "\n",
        "    Args:\n",
        "        part_a (dict): First part dictionary.\n",
        "        part_b (dict): Second part dictionary.\n",
        "\n",
        "    Returns:\n",
        "        float: IoU value between 0 and 1. Returns None if computation fails.\n",
        "    \"\"\"\n",
        "    min_a, max_a = extract_bounding_box(part_a)\n",
        "    min_b, max_b = extract_bounding_box(part_b)\n",
        "\n",
        "    if not min_a or not min_b:\n",
        "        return None  # Can't compute without bounding boxes\n",
        "\n",
        "    def volume(min_pt: Dict, max_pt: Dict) -> float:\n",
        "        dx = max_pt[\"x\"] - min_pt[\"x\"]\n",
        "        dy = max_pt[\"y\"] - min_pt[\"y\"]\n",
        "        dz = max_pt[\"z\"] - min_pt[\"z\"]\n",
        "        return max(0, dx) * max(0, dy) * max(0, dz)\n",
        "\n",
        "    inter_min = {\n",
        "        \"x\": max(min_a[\"x\"], min_b[\"x\"]),\n",
        "        \"y\": max(min_a[\"y\"], min_b[\"y\"]),\n",
        "        \"z\": max(min_a[\"z\"], min_b[\"z\"]),\n",
        "    }\n",
        "    inter_max = {\n",
        "        \"x\": min(max_a[\"x\"], max_b[\"x\"]),\n",
        "        \"y\": min(max_a[\"y\"], max_b[\"y\"]),\n",
        "        \"z\": min(max_a[\"z\"], max_b[\"z\"]),\n",
        "    }\n",
        "\n",
        "    inter_vol = volume(inter_min, inter_max)\n",
        "    union_vol = volume(min_a, max_a) + volume(min_b, max_b) - inter_vol\n",
        "\n",
        "    if union_vol == 0:\n",
        "        return 0.0\n",
        "    return inter_vol / union_vol"
      ],
      "metadata": {
        "id": "mztDWP3jEVJl"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. Part Feature Checks  \n",
        "Geometry-specific validations for individual parts, such as planarity, extrusion alignment, volume checks, and anchor symmetry.\n"
      ],
      "metadata": {
        "id": "BXBwnjyOExn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_extrusion_path_alignment(part: Dict) -> bool:\n",
        "    \"\"\"\n",
        "    Check if an extrusion's path is aligned along a principal axis (X, Y, or Z).\n",
        "\n",
        "    Args:\n",
        "        part (dict): Part dictionary with 'path' key containing a list of 3D points.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if path is well-aligned along one axis, False otherwise.\n",
        "    \"\"\"\n",
        "    path = part.get(\"path\", [])\n",
        "    if len(path) < 2:\n",
        "        return False\n",
        "\n",
        "    start, end = path[0], path[-1]\n",
        "    dx, dy, dz = end[\"x\"] - start[\"x\"], end[\"y\"] - start[\"y\"], end[\"z\"] - start[\"z\"]\n",
        "    length = (dx**2 + dy**2 + dz**2)**0.5\n",
        "    if length == 0:\n",
        "        return False\n",
        "\n",
        "    # Check if direction is mostly along one axis\n",
        "    nx, ny, nz = abs(dx / length), abs(dy / length), abs(dz / length)\n",
        "    return max(nx, ny, nz) > 0.99\n",
        "\n",
        "\n",
        "def check_profile_planarity(profile: List[Dict]) -> bool:\n",
        "    \"\"\"\n",
        "    Validate that all points in a profile lie on the same Z-plane.\n",
        "\n",
        "    Args:\n",
        "        profile (List[dict]): List of 3D points.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if profile is planar in Z-direction.\n",
        "    \"\"\"\n",
        "    z_values = [round(p[\"z\"], 4) for p in profile]\n",
        "    return len(set(z_values)) == 1\n",
        "\n",
        "\n",
        "def compute_part_volume(part: Dict) -> float:\n",
        "    \"\"\"\n",
        "    Compute an approximate volume of a part.\n",
        "\n",
        "    Currently only supports:\n",
        "    - Cuboids (from min/max points)\n",
        "\n",
        "    Args:\n",
        "        part (dict): Part dictionary.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated volume in cubic units. Returns 0 for unsupported shapes.\n",
        "    \"\"\"\n",
        "    shape = part.get(\"shape\")\n",
        "    if shape == \"cuboid\":\n",
        "        min_pt = part.get(\"min_point\", {})\n",
        "        max_pt = part.get(\"max_point\", {})\n",
        "        dx = max_pt.get(\"x\", 0) - min_pt.get(\"x\", 0)\n",
        "        dy = max_pt.get(\"y\", 0) - min_pt.get(\"y\", 0)\n",
        "        dz = max_pt.get(\"z\", 0) - min_pt.get(\"z\", 0)\n",
        "        return dx * dy * dz\n",
        "    return 0  # Volume estimation not supported for other shapes yet\n",
        "\n",
        "\n",
        "def check_anchor_symmetry(instances: List[Dict]) -> bool:\n",
        "    \"\"\"\n",
        "    Check whether a list of anchor parts are symmetrically placed along the X-axis.\n",
        "\n",
        "    Assumes symmetry across origin (X=0).\n",
        "\n",
        "    Args:\n",
        "        instances (List[dict]): List of anchor instances (revolutions).\n",
        "\n",
        "    Returns:\n",
        "        bool: True if anchors are symmetrically placed, False otherwise.\n",
        "    \"\"\"\n",
        "    xs = sorted([\n",
        "        round(i.get(\"axis_origin\", [0])[0], 2)\n",
        "        for i in instances if \"axis_origin\" in i\n",
        "    ])\n",
        "    if len(xs) < 2:\n",
        "        return False\n",
        "\n",
        "    for i in range(len(xs) // 2):\n",
        "        if abs(xs[i] + xs[-(i + 1)]) >= 0.1:\n",
        "            return False\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "vQt1SCVCFEct"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. Schema Validators  \n",
        "Checks whether structured output JSON files conform to the expected schema definitions using both custom logic and strict JSON Schema validation.\n"
      ],
      "metadata": {
        "id": "kwdvumh_FREW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_output_schema(data: dict) -> bool:\n",
        "    \"\"\"\n",
        "    Perform a basic sanity check on the structure of a structured output JSON.\n",
        "\n",
        "    This validator ensures:\n",
        "    - The \"bim\" section exists.\n",
        "    - Each part under \"bim.parts\" has a valid label and required fields.\n",
        "    - Revolution parts include required geometry fields.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Parsed JSON object.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if validation passes, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        assert \"bim\" in data, \"'bim' section missing\"\n",
        "        parts = data[\"bim\"].get(\"parts\", {})\n",
        "        assert isinstance(parts, dict), \"'bim.parts' must be a dictionary\"\n",
        "\n",
        "        for label, part in parts.items():\n",
        "            assert isinstance(label, str), \"Part label must be a string\"\n",
        "            assert isinstance(part, dict), \"Each part must be a dictionary\"\n",
        "            assert \"shape\" in part, f\"Part '{label}' missing required 'shape' field\"\n",
        "\n",
        "            if part[\"shape\"] == \"revolution\":\n",
        "                for field in [\"axis_origin\", \"axis_direction\", \"sweep_angle\"]:\n",
        "                    assert field in part, f\"Revolution part '{label}' missing '{field}'\"\n",
        "\n",
        "        return True\n",
        "\n",
        "    except AssertionError as e:\n",
        "        print(f\"❌ Schema sanity check failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def validate_output_schema_strict(data: dict, filename: str = \"\") -> bool:\n",
        "    \"\"\"\n",
        "    Validate structured output against the full JSON Schema definition.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Parsed JSON object.\n",
        "        filename (str): Optional filename for error reporting.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if schema validation succeeds, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        validate(instance=data, schema=STRUCTURED_OUTPUT_SCHEMA)\n",
        "        return True\n",
        "    except ValidationError as e:\n",
        "        print(f\"❌ Schema error in {filename}: {e.message}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def run_schema_validation(data: dict, filename: str = \"\") -> bool:\n",
        "    \"\"\"\n",
        "    Run both shallow and strict validations on structured JSON output.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Parsed JSON object.\n",
        "        filename (str): Optional filename for reporting.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all validations pass.\n",
        "    \"\"\"\n",
        "    if not validate_output_schema(data):\n",
        "        print(f\"❌ Failed shallow validation: {filename}\")\n",
        "        return False\n",
        "\n",
        "    if not validate_output_schema_strict(data, filename):\n",
        "        print(f\"❌ Failed strict schema validation: {filename}\")\n",
        "        return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "FM5zww8PFR6H"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. Batch Validation Logic  \n",
        "This section processes a folder of generated structured output files and, if available, compares them to ground-truth reference files.\n"
      ],
      "metadata": {
        "id": "6leQOicqFjlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_structured_outputs(generated_folder, reference_folder=None):\n",
        "    \"\"\"\n",
        "    Validate structured geometry outputs by performing schema checks and comparing to reference files.\n",
        "\n",
        "    Args:\n",
        "        generated_folder (str or Path): Folder containing *_structured_output.json files.\n",
        "        reference_folder (str or Path, optional): Folder with reference JSON files for comparison.\n",
        "\n",
        "    Returns:\n",
        "        None. Prints results and displays validation tables using pandas and IPython.\n",
        "    \"\"\"\n",
        "    generated_path = Path(generated_folder)\n",
        "    reference_path = Path(reference_folder) if reference_folder else None\n",
        "\n",
        "    generated_files = list(generated_path.glob(\"*_structured_output.json\"))\n",
        "    reference_files = list(reference_path.glob(\"*.json\")) if reference_folder else []\n",
        "\n",
        "    summary_rows = []\n",
        "\n",
        "    def match_reference(gen_file):\n",
        "        gen_prefix = gen_file.stem.replace(\"_structured_output\", \"\")\n",
        "        for ref in reference_files:\n",
        "            if ref.stem.startswith(gen_prefix):\n",
        "                return ref\n",
        "        return None\n",
        "\n",
        "    for gen_file in generated_files:\n",
        "        gen_data = load_json(gen_file)\n",
        "        if not run_schema_validation(gen_data, gen_file.name):\n",
        "            continue  # Skip invalid file\n",
        "\n",
        "        ref_file = match_reference(gen_file)\n",
        "\n",
        "        if not ref_file:\n",
        "            ref_data = None  # No reference data\n",
        "        else:\n",
        "            ref_data = load_json(ref_file)\n",
        "\n",
        "        # Validate content\n",
        "        gen_parts = gen_data.get(\"bim\", {}).get(\"parts\", {})\n",
        "\n",
        "        # --- Unsupervised quality checks (no GT needed) ---\n",
        "        unsupervised_issues = []\n",
        "        total_part_volume = 0\n",
        "\n",
        "        for label, part in gen_parts.items():\n",
        "            shape = part.get(\"shape\", \"\").lower()\n",
        "\n",
        "            # Compute part volume\n",
        "            part_volume = compute_part_volume(part)\n",
        "            total_part_volume += part_volume\n",
        "\n",
        "            # Check extrusion alignment\n",
        "            if shape == \"extrusion\" and not check_extrusion_path_alignment(part):\n",
        "                unsupervised_issues.append(f\" {label}: misaligned extrusion axis\")\n",
        "\n",
        "            # Check profile planarity\n",
        "            if shape in {\"extrusion\", \"revolution\"} and not check_profile_planarity(part.get(\"profile\", [])):\n",
        "                unsupervised_issues.append(f\" {label}: non-planar profile\")\n",
        "\n",
        "            # Check anchor symmetry if labeled accordingly\n",
        "            if label.startswith(\"anchors\") and not check_anchor_symmetry(part.get(\"instances\", [])):\n",
        "                unsupervised_issues.append(f\" {label}: anchor symmetry issue\")\n",
        "\n",
        "            # Symmetry check for parts labeled with 'anchor'\n",
        "            if \"anchor\" in label.lower() and not check_anchor_symmetry(part.get(\"instances\", [])):\n",
        "                unsupervised_issues.append(f\" {label}: anchor symmetry issue\")\n",
        "\n",
        "            # Shape-specific field checks\n",
        "            if shape == \"extrusion\":\n",
        "                if \"path\" not in part or not isinstance(part[\"path\"], list):\n",
        "                    unsupervised_issues.append(f\" {label}: missing or invalid 'path' for extrusion\")\n",
        "\n",
        "            if shape == \"revolution\":\n",
        "                if \"axis_origin\" not in part:\n",
        "                    unsupervised_issues.append(f\" {label}: missing 'axis_origin' for revolution\")\n",
        "                if \"sweep_angle\" in part and not (0 < part[\"sweep_angle\"] <= 360):\n",
        "                    unsupervised_issues.append(f\" {label}: sweep_angle out of bounds (0–360)\")\n",
        "\n",
        "            # Generic numeric sanity checks\n",
        "            origin = part.get(\"origin\", {})\n",
        "            if any(origin.get(dim, 0) != origin.get(dim, 0) for dim in (\"x\", \"y\", \"z\")):  # NaN check\n",
        "                unsupervised_issues.append(f\" {label}: invalid origin coordinates (NaN)\")\n",
        "\n",
        "            profile = part.get(\"profile\", [])\n",
        "            for i, pt in enumerate(profile):\n",
        "                for dim in (\"x\", \"y\", \"z\"):\n",
        "                    val = pt.get(dim)\n",
        "                    if not isinstance(val, (int, float)) or not math.isfinite(val):\n",
        "                        unsupervised_issues.append(f\" {label}: profile point {i} has invalid {dim}={val}\")\n",
        "\n",
        "        # Estimate bounding box volume and part coverage\n",
        "        bbox_volume = compute_part_volume(gen_parts.get(\"bounding_box\", {}))\n",
        "        coverage_ratio = total_part_volume / bbox_volume if bbox_volume else 0\n",
        "\n",
        "        if coverage_ratio < 0.05:\n",
        "            unsupervised_issues.append(\" volume coverage too low (<5%)\")\n",
        "        elif coverage_ratio > 1.5:\n",
        "            unsupervised_issues.append(\" volume coverage too high (>150%)\")\n",
        "\n",
        "        # --- Initialize variables for errors ---\n",
        "        iou_results = []\n",
        "        origin_errors = []\n",
        "        profile_errors = []\n",
        "        cutout_results = []\n",
        "\n",
        "        if ref_data:\n",
        "            ref_parts = ref_data.get(\"bim\", {}).get(\"parts\", {})\n",
        "\n",
        "            # --- Compute bounding box IoU for all supported shapes ---\n",
        "            shared_labels = set(gen_parts.keys()) & set(ref_parts.keys())\n",
        "            for label in shared_labels:\n",
        "                gen_part = gen_parts[label]\n",
        "                ref_part = ref_parts[label]\n",
        "\n",
        "                iou = compute_bounding_box_iou(gen_part, ref_part)\n",
        "                if iou is not None:\n",
        "                    iou_results.append({\n",
        "                        \"File\": gen_file.name,\n",
        "                        \"Label\": label,\n",
        "                        \"Shape\": gen_part.get(\"shape\"),\n",
        "                        \"IoU\": round(iou, 3)\n",
        "                    })\n",
        "\n",
        "            # --- Compute origin placement error for parts with 'origin' ---\n",
        "            for label in shared_labels:\n",
        "                gen_part = gen_parts[label]\n",
        "                ref_part = ref_parts[label]\n",
        "\n",
        "                if \"origin\" in gen_part and \"origin\" in ref_part:\n",
        "                    origin_err = euclidean_distance_3d(gen_part[\"origin\"], ref_part[\"origin\"])\n",
        "                    origin_errors.append({\n",
        "                        \"File\": gen_file.name,\n",
        "                        \"Label\": label,\n",
        "                        \"Origin Error\": round(origin_err, 4)\n",
        "                    })\n",
        "\n",
        "            # --- Compare profile geometry (for extrusions and revolutions) ---\n",
        "            for label in shared_labels:\n",
        "                gen_part = gen_parts[label]\n",
        "                ref_part = ref_parts[label]\n",
        "\n",
        "                if gen_part.get(\"shape\") in {\"extrusion\", \"revolution\"} and ref_part.get(\"shape\") == gen_part.get(\"shape\"):\n",
        "                    profile_err = mean_profile_distance(gen_part, ref_part)\n",
        "                    if profile_err is not None:\n",
        "                        profile_errors.append({\n",
        "                            \"File\": gen_file.name,\n",
        "                            \"Label\": label,\n",
        "                            \"Profile Error\": round(profile_err, 4)\n",
        "                        })\n",
        "\n",
        "            for label in shared_labels:\n",
        "                gen_part = gen_parts[label]\n",
        "                ref_part = ref_parts[label]\n",
        "\n",
        "                gen_cutouts = gen_part.get(\"cutouts\", [])\n",
        "                ref_cutouts = ref_part.get(\"cutouts\", [])\n",
        "\n",
        "                if isinstance(gen_cutouts, list) and isinstance(ref_cutouts, list):\n",
        "                    tp = min(len(gen_cutouts), len(ref_cutouts))  # assumed matched cutouts\n",
        "                    fp = max(0, len(gen_cutouts) - len(ref_cutouts))\n",
        "                    fn = max(0, len(ref_cutouts) - len(gen_cutouts))\n",
        "\n",
        "                    precision = tp / (tp + fp) if (tp + fp) else 0\n",
        "                    recall = tp / (tp + fn) if (tp + fn) else 0\n",
        "                    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
        "\n",
        "                    cutout_results.append({\n",
        "                        \"File\": gen_file.name,\n",
        "                        \"Label\": label,\n",
        "                        \"Gen Cutouts\": len(gen_cutouts),\n",
        "                        \"Ref Cutouts\": len(ref_cutouts),\n",
        "                        \"Precision\": round(precision, 2),\n",
        "                        \"Recall\": round(recall, 2),\n",
        "                        \"F1 Score\": round(f1, 2)\n",
        "                    })\n",
        "\n",
        "        # Label counts\n",
        "        gen_labels = Counter(gen_parts.keys())\n",
        "        ref_labels = Counter(ref_parts.keys()) if ref_data else {}\n",
        "\n",
        "        gen_shapes = Counter(p.get(\"shape\", \"unknown\") for p in gen_parts.values() if isinstance(p, dict))\n",
        "        ref_shapes = Counter(p.get(\"shape\", \"unknown\") for p in ref_parts.values() if isinstance(p, dict)) if ref_data else {}\n",
        "\n",
        "        # Scores\n",
        "        matched_labels = set(gen_labels.keys()) & set(ref_labels.keys()) if ref_data else set(gen_labels.keys())\n",
        "        label_precision = len(matched_labels) / len(gen_labels) if gen_labels else 0\n",
        "        label_recall = len(matched_labels) / len(ref_labels) if ref_labels else 0\n",
        "\n",
        "        matched_shapes = set(gen_shapes.keys()) & set(ref_shapes.keys()) if ref_data else set(gen_shapes.keys())\n",
        "        shape_accuracy = len(matched_shapes) / len(ref_shapes) if ref_shapes else 0\n",
        "\n",
        "        generalization_score = (label_precision + label_recall + shape_accuracy) / 3\n",
        "\n",
        "        # Bounding box presence\n",
        "        has_bbox = \"bounding_box\" in gen_parts or any(\"bounding_box\" in k for k in gen_parts)\n",
        "\n",
        "        summary = {\n",
        "            \"File\": gen_file.name,\n",
        "            \"Part Count\": len(gen_parts),\n",
        "            \"Label Count\": len(gen_labels),\n",
        "            \"Shape Count\": len(gen_shapes),\n",
        "            \"Has Bounding Box\": has_bbox,\n",
        "        }\n",
        "\n",
        "        if ref_file:\n",
        "            summary.update({\n",
        "                \"Part Count Error\": abs(len(gen_parts) - len(ref_parts)),\n",
        "                \"Label Precision\": round(label_precision, 2),\n",
        "                \"Label Recall\": round(label_recall, 2),\n",
        "                \"Shape Accuracy\": round(shape_accuracy, 2),\n",
        "                \"Generalization Score\": round(generalization_score, 2),\n",
        "            })\n",
        "        else:\n",
        "            summary.update({\n",
        "                \"Part Count Error\": \"N/A\",\n",
        "                \"Label Precision\": round(label_precision, 2),\n",
        "                \"Label Recall\": \"N/A\",\n",
        "                \"Shape Accuracy\": \"N/A\",\n",
        "                \"Generalization Score\": \"N/A\",\n",
        "            })\n",
        "\n",
        "        summary_rows.append(summary)\n",
        "\n",
        "\n",
        "        # --- Per-label metrics ---\n",
        "        all_labels = set(ref_labels.keys()) | set(gen_labels.keys()) if ref_data else set(gen_labels.keys())\n",
        "        label_metrics = []\n",
        "\n",
        "        for label in sorted(all_labels):\n",
        "            tp = int(label in gen_labels and label in ref_labels) if ref_data else 0\n",
        "            fp = int(label in gen_labels and label not in ref_labels) if ref_data else 0\n",
        "            fn = int(label in ref_labels and label not in gen_labels) if ref_data else 0\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
        "\n",
        "            label_metrics.append({\n",
        "                \"File\": gen_file.name,\n",
        "                \"Label\": label,\n",
        "                \"TP\": tp,\n",
        "                \"FP\": fp,\n",
        "                \"FN\": fn,\n",
        "                \"Precision\": round(precision, 2),\n",
        "                \"Recall\": round(recall, 2),\n",
        "                \"F1 Score\": round(f1, 2)\n",
        "            })\n",
        "\n",
        "        label_metrics_df = pd.DataFrame(label_metrics)\n",
        "        iou_df = pd.DataFrame(iou_results)\n",
        "        if not iou_df.empty:\n",
        "            print(\"\\n Bounding Box IoU (Cuboid, Extrusion, Revolution)\")\n",
        "            display(iou_df)\n",
        "\n",
        "        origin_df = pd.DataFrame(origin_errors)\n",
        "        if not origin_df.empty:\n",
        "            print(\"\\n Origin Placement Error (Euclidean Distance)\")\n",
        "            display(origin_df)\n",
        "\n",
        "            profile_df = pd.DataFrame(profile_errors)\n",
        "            if not profile_df.empty:\n",
        "                print(\"\\n Profile Geometry Error (Mean Vertex Distance)\")\n",
        "                display(profile_df)\n",
        "\n",
        "            cutout_df = pd.DataFrame(cutout_results)\n",
        "            if not cutout_df.empty:\n",
        "                print(\"\\n Cutout Count Accuracy\")\n",
        "                display(cutout_df)\n",
        "\n",
        "            # Print details\n",
        "            print(f\"\\n {gen_file.name}\")\n",
        "            if unsupervised_issues:\n",
        "                print(\" Unsupervised Validation Issues:\")\n",
        "                for issue in unsupervised_issues:\n",
        "                    print(f\"   {issue}\")\n",
        "            else:\n",
        "                print(\" Unsupervised checks passed.\")\n",
        "            print(f\" Labels: {dict(gen_labels)}\")\n",
        "            print(f\" Shapes: {dict(gen_shapes)}\")\n",
        "\n",
        "        # Summary\n",
        "        if not summary_rows:\n",
        "            print(\"\\n No valid structured-reference matches were found.\")\n",
        "            return\n",
        "\n",
        "        summary_df = pd.DataFrame(summary_rows)\n",
        "        print(\"\\n Validation Summary\")\n",
        "        display(summary_df)\n",
        "\n",
        "        score_cols = [\"File\", \"Label Precision\", \"Label Recall\", \"Shape Accuracy\", \"Generalization Score\"]\n",
        "        if all(col in summary_df.columns for col in score_cols):\n",
        "            print(\"\\n Scoring Overview\")\n",
        "            display(summary_df[score_cols])\n"
      ],
      "metadata": {
        "id": "uWFmLGc6FmB4"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. File Paths  \n",
        "Define where the validator will read structured output files from, and (optionally) where the ground truth reference files are located.\n",
        "\n",
        "If no reference is available, only a generated folder is needed.  \n",
        "If reference validation is desired, provide both.\n"
      ],
      "metadata": {
        "id": "a_IHJh4LGx3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output directories for processing\n",
        "# Set your actual folder paths here\n",
        "parts_folder = Path(\"\")\n",
        "reference_folder = Path(\"\")  # Optional"
      ],
      "metadata": {
        "id": "gkzwJH-kJx9N"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Execute Validator  \n",
        "This section runs validation on all structured output JSON files in the given folder.  \n",
        "If a reference folder is provided, comparison will also be performed.\n"
      ],
      "metadata": {
        "id": "bmdnAc8zHIkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validate_structured_outputs(parts_folder, reference_folder)"
      ],
      "metadata": {
        "id": "okBJaJh8_Epm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Notes\n",
        "\n",
        "This notebook is part of a **four-step modular pipeline** for extracting and validating BIM-ready geometry from structural engineering drawings.\n",
        "\n",
        "### Output Location\n",
        "- Validation results are displayed in the notebook via dataframes and printed logs.\n",
        "- No new files are written unless extended for report generation.\n",
        "\n",
        "### How to Run\n",
        "1. Set your `parts_folder` (and optionally `reference_folder`) paths in **Section 3**.\n",
        "2. Ensure structured output files (`*_structured_output.json`) exist in the input folder.\n",
        "3. If reference data is available, place ground truth JSON files in the reference folder.\n",
        "4. Run all cells from top to bottom to validate schema and geometry.\n",
        "\n",
        "### Next Step\n",
        "- This is the final step in the pipeline. Review any flagged validation issues.\n",
        "\n",
        "### Documentation\n",
        "For full setup instructions and pipeline details, see the [README.md](https://github.com/ThadaMan/Thesis/blob/main/README.md) in the repository.\n"
      ],
      "metadata": {
        "id": "RcuAPH3y9Usd"
      }
    }
  ]
}